# Big_Mart_Sales_Prediction

## Data Collection and Preliminary Analysis:
1. Data is loaded from a CSV file into a pandas DataFrame.
2. Initial exploration includes examining the first few rows, the shape of the dataset, and checking for missing values.
3. Summary statistics and information about data types of the columns are displayed.
4. Missing values in the columns Item_Weight and Outlet_Size are handled by imputing with mean and mode, respectively.
## Data Visualization:
1. Distribution plots for numerical features (Item_Weight, Item_Visibility, Item_MRP, Item_Outlet_Sales) and count plots for categorical features (Outlet_Establishment_Year, Item_Fat_Content, Item_Type, Outlet_Size) are created using seaborn to understand data distribution and presence of categorical data.
## Data Pre-Processing:
1. Categorical variables are identified, and inconsistencies in Item_Fat_Content are corrected.
2. Label encoding is applied to convert categorical features into numerical format, making them suitable for the model.
## Model Preparation:
1. Features and target variable (Item_Outlet_Sales) are separated into x and y respectively.
2. Data is split into training and testing sets to evaluate the model's performance on unseen data.
## Model Training:
1. An XGBoost regressor model is instantiated and trained on the training data.
## Model Evaluation:
1. Model's performance is evaluated using the R-squared metric on both training and testing sets.
2. Results indicate a good fit on the training data with an R-squared value of 0.8762 but a moderate fit on the test data with an R-squared value of 0.5017, suggesting that the model may be overfitting to the training data.
## Insights:
1. The process includes all necessary steps from data loading, preprocessing (handling missing values and label encoding), to model training and evaluation.
2. Visualization helps in understanding the distribution of data and the relationship between features and the target variable.
3. The difference in performance metrics between training and testing sets suggests the need for model tuning or exploring other models to improve generalization on unseen data.
4. It's important to explore feature engineering, model hyperparameter tuning, or alternative modeling techniques to enhance the model's predictive performance.
